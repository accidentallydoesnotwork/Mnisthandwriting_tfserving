{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow low level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a matrix kinda like np.array([])\n",
    "t = tf.constant([[1.,2.,3.], [4.,5.,6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=119, shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defines scalar \n",
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=123, shape=(2, 1), dtype=float32, numpy=\n",
       "array([[3.],\n",
       "       [6.]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing works like Numpy: row then col \n",
    "t[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=132, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor operation \n",
    "t + 10\n",
    "tf.square(t)\n",
    "t @ tf.transpose(t) # matrix multiplication equal to tf.matmul()\n",
    "tf.matmul(t, tf.transpose(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor and Numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So when you create a tensor from a NumPy array, make sure to set dtype=tf.float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=133, shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert numpy to tensor \n",
    "a = np.array([2.,4.,5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tensor to numpy\n",
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=135, shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply tensor OP directly to np.array\n",
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply numpy OP directly to a tensor \n",
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.constant and tf.variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main differences: tf.tensor create from tf.constant so far are immutable: you cannot modify them. This means that we cannot use regular tensors to implement weights in a neural network, since they need to be tweaked by backpropagation. Plus, other parameters may also need to change over time. Thus we need a tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf_variable can be modified using assign() method\n",
    "v.assign(2 * v)           # => [[2., 4., 6.], [8., 10., 12.]]\n",
    "v[0, 1].assign(42)        # => [[2., 42., 6.], [8., 10., 12.]]\n",
    "v[:, 2].assign([0., 1.])  # => [[2., 42., 0.], [8., 10., 1.]]\n",
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])\n",
    "                          # => [[100., 42., 0.], [8., 10., 200.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Sparse tensors (tf.SparseTensor)\n",
    "\n",
    "    Efficiently represent tensors containing mostly zeros. The tf.sparse package contains operations for sparse tensors.\n",
    "\n",
    "2) Tensor arrays (tf.TensorArray)\n",
    "\n",
    "    Are lists of tensors. They have a fixed size by default but can optionally be made dynamic. All tensors they contain must have the same shape and data type.\n",
    "\n",
    "3) Ragged tensors (tf.RaggedTensor)\n",
    "\n",
    "    Represent static lists of lists of tensors, where every tensor has the same shape and data type. The tf.ragged package contains operations for ragged tensors.\n",
    "\n",
    "4) String tensors\n",
    "\n",
    "    Are regular tensors of type tf.string. These represent byte strings, not Unicode strings, so if you create a string tensor using a Unicode string (e.g., a regular Python 3 string like \"café\"), then it will get encoded to UTF-8 automatically (e.g., b\"caf\\xc3\\xa9\"). Alternatively, you can represent Unicode strings using tensors of type tf.int32, where each item represents a Unicode code point (e.g., [99, 97, 102, 233]). The tf.strings package (with an s) contains ops for byte strings and Unicode strings (and to convert one into the other). It’s important to note that a tf.string is atomic, meaning that its length does not appear in the tensor’s shape. Once you convert it to a Unicode tensor (i.e., a tensor of type tf.int32 holding Unicode code points), the length appears in the shape.\n",
    "\n",
    "5) Sets\n",
    "\n",
    "    Are represented as regular tensors (or sparse tensors). For example, tf.constant([[1, 2], [3, 4]]) represents the two sets {1, 2} and {3, 4}. More generally, each set is represented by a vector in the tensor’s last axis. You can manipulate sets using operations from the tf.sets package.\n",
    "\n",
    "6) Queues\n",
    "\n",
    "    Store tensors across multiple steps. TensorFlow offers various kinds of queues: simple First In, First Out (FIFO) queues (FIFOQueue), queues that can prioritize some items (PriorityQueue), shuffle their items (RandomShuffleQueue), and batch items of different shapes by padding (PaddingFIFOQueue). These classes are all in the tf.queue package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras low level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras low level api \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=166, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all keras OP is kinda like tensorflow. \n",
    "# we use keras backend when we want to export our code to keras\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement Huber Loss \n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to your keras model\n",
    "# model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
    "# model.fit(X_train, y_train, [...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models That Contain Custom Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "#                                 custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/coderschool/deploying/mnist_fansipan/model_train'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 12)        108       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 12)        36        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 24)        10368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 14, 14, 24)        72        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 14, 14, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 32)          27648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 7, 7, 32)          96        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200)               313600    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 200)               600       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 354,538\n",
      "Trainable params: 354,002\n",
      "Non-trainable params: 536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor layer \n",
    "class Preprocessor(keras.layers.Layer):\n",
    "    def preprocess(self, data): \n",
    "        img_raw = data\n",
    "        image = tf.image.decode_jpeg(img_raw, channels=1)\n",
    "        image = tf.image.resize(image, [28, 28])\n",
    "        image = (255 - image) / 255.0  # normalize to [0,1] range\n",
    "        image = tf.reshape(image, (1, 28, 28, 1))\n",
    "    \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular_inputs = keras.layers.Input(shape=[8])\n",
    "# categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "# cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "# cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
    "# encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "# outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "# model = keras.models.Model(inputs=[regular_inputs, categories],\n",
    "#                            outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tf1 code \n",
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# string_inp = tf.compat.v1.placeholder(tf.string, shape=(None,))\n",
    "# imgs_map = tf.map_fn(\n",
    "#     tf.image.decode_image,\n",
    "#     string_inp,\n",
    "#     dtype=tf.uint8\n",
    "# )\n",
    "# imgs_map.set_shape((None, None, None, 3))\n",
    "# imgs = tf.image.resize_images(imgs_map, [28, 28])\n",
    "# imgs = tf.reshape(imgs, (-1, 28, 28, 3))\n",
    "# img_float = tf.cast(imgs, dtype=tf.float32) / 255\n",
    "\n",
    "# model = tf.keras.models.load_model('../saved_model/my_model')\n",
    "# output = model(img_float)\n",
    "\n",
    "# # saved model\n",
    "# version = 2\n",
    "# export_path = os.path.join('classifier', str(version))\n",
    "# tf.saved_model.simple_save(\n",
    "#     tf.keras.backend.get_session(),\n",
    "#     export_path,\n",
    "#     inputs={'input_image': string_inp},\n",
    "#     outputs={'predictions': output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
